{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ede4f2-475e-4b44-b976-ce8867533c6d",
   "metadata": {},
   "source": [
    "![alt text](img/MIoT_ML.png \"MIoT_ML\")\n",
    "# Unidad 04  Entrenamiento de Modelos de Aprendizaje Automático\n",
    "\n",
    "El objetivo principal de esta práctica es el desarrollo, optimización y evaluación de un modelo de Aprendizaje Automático.\n",
    "\n",
    "El Notebook contiene varios ejercicios sencillos. Debéis desarrollarlos durante la clase y subirlos al aula virtual.\n",
    "\n",
    "## Referencias útiles para la práctica\n",
    "1. API Pandas: [https://pandas.pydata.org/docs/reference/index.html](https://pandas.pydata.org/docs/reference/index.html)\n",
    "2. API Scikit-learn: [https://scikit-learn.org/stable/api/index.html](https://scikit-learn.org/stable/api/index.html)\n",
    "3. Dataset para el ejercicio: [https://www.kaggle.com/datasets/camnugent/california-housing-prices](https://www.kaggle.com/datasets/camnugent/california-housing-prices)\n",
    "4. Géron, Aurélien. Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow. \" O'Reilly Media, Inc.\", 2022.\n",
    "5. Bergstra, J., & Bengio, Y. (2012). Random search for hyperparameter optimization. Journal of machine learning research, 13 (2). *Para profundizar en la optimización de hiperparámetros*\n",
    "   \n",
    "## 1. Flujo de trabajo básico en problemas de Aprendizaje Automático (*ML workflow*)\n",
    "A la hora de enfrentarnos a un nuevo problema de Aprendizaje Automático (ML), existen una serie de pasos típicos y comunes que debemos afrontar:\n",
    "1. Entender el problema y su contexto.\n",
    "2. Obtener los datos (histórico).\n",
    "3. Explorar, analizar y entender los datos.\n",
    "4. Preparar los datos para los modelos.\n",
    "5. Seleccionar, optimizar y entrenar los modelos ML.\n",
    "6. Evaluar y presentar el modelo seleccionado.\n",
    "7. Desplegar, monitorizar y mantener la solución.\n",
    "\n",
    "En esta unidad nos centraremos en los pasos 5 y 6 del flujo de trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5e0bf0-097f-41db-9f17-8abf8aeb723f",
   "metadata": {},
   "source": [
    "## 2. Carga y partición de datos\n",
    "### 2.1. Carga de los datos\n",
    "Cargaremos los datos generados durante la Unidad02, almacenados al finalizar la misma. Suponemos que se han mantenido los nombres generados durante dicha unidad, y que los datos están almacenados en el directorio raíz.\n",
    "\n",
    "- Características de entrada preprocesadas (*Inputs*) de las observaciones del conjunto de entrenamiento (*preprocessing_trainset_inputs.csv*).\n",
    "- Etiquetas de salida (*Outputs*) de las observaciones del conjunto de entrenamiento (*trainset_ouputs.csv*).\n",
    "- Características de entrada preprocesadas (*Inputs*) de las observaciones del conjunto de Test (*preprocessing_testset_inputs.csv*).\n",
    "- Etiquetas de salida (*Outputs*) de las observaciones del conjunto de Test (*testset_outputs.csv*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98859249-f101-4d2e-bc90-7b4309a4363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas library\n",
    "import pandas as pd\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError as err:\n",
    "    !pip install pandas\n",
    "    import pandas as pd\n",
    "\n",
    "\n",
    "training_inputs = pd.read_csv(\"./preprocessing_trainset_inputs.csv\", index_col=\"idx\")\n",
    "training_outputs = pd.read_csv(\"./trainset_ouputs.csv\", index_col=\"idx\")\n",
    "print(\"Longitud del conjunto de entrenamiento:\", len(training_inputs))\n",
    "\n",
    "testing_inputs = pd.read_csv(\"./preprocessing_testset_inputs.csv\", index_col=\"idx\")\n",
    "testing_outputs = pd.read_csv(\"./testset_outputs.csv\", index_col=\"idx\")\n",
    "print(\"Longitud del conjunto de test:\", len(testing_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18407a45-c5fa-4770-ac57-66053185940e",
   "metadata": {},
   "source": [
    "### 2.2. Creación del conjunto de validación\n",
    "\n",
    "Vamos a dividir el conjunto de test original en dos conjuntos de igual tamaño: el conjunto de validación, que emplearemos para seleccionar los hiperparámetros que den mejores resultados; y el conjunto de test propiamente dicho, que emplearemos para medir la calidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fbb504-b200-4845-89f3-dc48a3b8278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except ImportError as err:\n",
    "    !pip install sklearn\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED=1234\n",
    "\n",
    "# dividimos el conjunto de test original: testing_inputs\n",
    "test_inputs, val_inputs = train_test_split(testing_inputs, test_size=0.5, train_size=0.5, random_state=SEED, shuffle=True)\n",
    "\n",
    "# generamos los outputs correspondientes a los dos conjuntos creados\n",
    "val_outputs = testing_outputs.loc[val_inputs.index]\n",
    "print(\"Longitud del conjunto de validación:\", len(val_outputs))\n",
    "\n",
    "test_outputs = testing_outputs.loc[test_inputs.index]\n",
    "print(\"Longitud del conjunto de test:\", len(test_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e8148c-7435-4ae2-924f-d185acfbfa1b",
   "metadata": {},
   "source": [
    "### Selección de una métrica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95addb48-56fe-4d4c-9571-b16a22a9a96f",
   "metadata": {},
   "source": [
    "### Creación de un modelo básico\n",
    "\n",
    "**Nota**: se puede añadir al propio pipeline de preprocesao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3f1a8-207d-4a49-ac4b-1a253834ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_lin_reg = LinearRegression()\n",
    "model_lin_reg.fit(training_inputs, training_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d78a1-7719-44f5-a58b-ea2aa44926f0",
   "metadata": {},
   "source": [
    "### Evaluación de un modelo básico\n",
    "#### Evaluación con el dataset de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3cd1c-b3f2-49f2-aa01-1d1c5b890490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "training_predictions = model_lin_reg.predict(training_inputs)\n",
    "\n",
    "print(\"Primeras 5 observaciones del entrenamiento\")\n",
    "for real, pred in zip(training_predictions[:5].round(-2) ,training_outputs.iloc[:5].values):\n",
    "    print(f\"Valor real: {real}, valor predicho: {pred}. Diferencia en absoluto{abs(real-pred)}. Porcentaje desvío: {(abs(real-pred)*100/real).round(2)}%\")\n",
    "\n",
    "\n",
    "# lin_reg_rmse = root_mean_squared_error(traini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cd154b-0939-48de-a86b-fc16dafbd26e",
   "metadata": {},
   "source": [
    "##### Cálculo de las métricas para todo el dataset de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7467dd-0e9d-47ba-809f-4cef8ff4533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "rmse_train = root_mean_squared_error(training_outputs, training_predictions)\n",
    "print(f\"RMSE de entrenamiento con modelo de regresión lineal: {rmse_train.round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5082d1b-4355-48a1-9062-11c997cf6564",
   "metadata": {},
   "source": [
    "#### Prueba de otro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c67395-6142-40f6-9f5f-bc3c3a816ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model_tree = DecisionTreeRegressor(random_state=SEED)\n",
    "model_tree.fit(training_inputs, training_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe963bb-0a8a-4865-a778-153b2bc90110",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = model_tree.predict(training_inputs)\n",
    "\n",
    "print(\"Primeras 5 observaciones del entrenamiento\")\n",
    "for real, pred in zip(training_predictions[:5].round(-2),training_outputs.iloc[:5].values):\n",
    "    print(f\"Valor real: {real}, valor predicho: {pred}. Diferencia en absoluto{abs(real-pred)}. Porcentaje desvío: {(abs(real-pred)*100/real).round(2)}%\")\n",
    "\n",
    "rmse_train  =root_mean_squared_error(training_outputs, training_predictions)\n",
    "print(f\"RMSE de entrenamiento con modelo de árbol de decisión: {rmse_train.round(2)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5ebd9-cdaf-4c80-a800-2d0581311d7c",
   "metadata": {},
   "source": [
    "**¿Qué ha pasado? ¿Cómo puede ser que no tenga ningún error?**\n",
    "\n",
    "**EJERCICIO**\n",
    "Explica en una celda de texto qué puede estar pasando para que no exista error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67121e97-976d-42e9-adbc-00694f8dc548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO\n",
    "# Explica en esta celda de texto que puede estar pasando para que no exista error\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c6918c-94de-48c5-8ec8-8cf866e4ce9f",
   "metadata": {},
   "source": [
    "#### Evaluación con un conjunto de datos no visto previamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d797236-23f9-4b06-8ed8-9e107a2a89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación con el dataset de Validación para el modelo de regresión lineal\n",
    "val_predictions = model_lin_reg.predict(val_inputs)\n",
    "rmse_val = root_mean_squared_error(val_outputs, val_predictions)\n",
    "print(f\"RMSE de Validación con modelo de regresión lineal: {rmse_val.round(2)}\")\n",
    "\n",
    "# Evaluación con el dataset de Validación para el modelo de árbol de decisión\n",
    "\n",
    "val_predictions = model_tree.predict(val_inputs)\n",
    "rmse_val = root_mean_squared_error(val_outputs, val_predictions)\n",
    "print(f\"RMSE de Validación con el modelo árbol de decisión: {rmse_val.round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bacc25-0196-4230-a689-98f9be8332da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a36a27ab-06d1-4c5d-a2a0-8571925768f4",
   "metadata": {},
   "source": [
    "### selección de características\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598a6f5c-b801-4ab4-a014-b011ba9bdc2d",
   "metadata": {},
   "source": [
    "#### Filtros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00f30c4-cce4-43e9-bd9a-6100a2e371bc",
   "metadata": {},
   "source": [
    "#### Embebidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0468f-42b1-47c5-a54b-53c269cec631",
   "metadata": {},
   "source": [
    "#### Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34022bb-8464-4291-8d63-ad302adcc0fb",
   "metadata": {},
   "source": [
    "### Optimización de hiperparámetros\n",
    "Los algoritmos de ML tienen una serie de parámetros de configuración que afectan al entrenamiento del modelo y posteriormente al desempeño de este (ej. LR, momento, etc.). Los parámetros por defecto raras veces son los óptimos, y es necesario optimizarlos para cada problema concreto. Este es un proceso muy costoso computacionalmente, y que requiere muchas veces de recursos dedicados. Existen diferentes técnicas para realizar la optimización (ej. GRID, aleatoria, evolutiva, etc.). La más básica es la optimización basada en una búsqueda GRID.\n",
    "\n",
    "#### Grid Search\n",
    "\n",
    "La optimización GRID es la prueba exhaustiva de todas las combinaciones posibles de varios parámetros. Para aplicarla, lo primero que necesitamos es establecer los rangos de valores que queremos probar. La prueba exhaustiva es el equivalente a probar todas las combinaciones empleando bucles “for” anidados. Las optimizaciones de hiperparámetros se hacen y se comparan a través de un conjunto de validación (o empleando validación cruzada), pero nunca contra el conjunto de test).\n",
    "\n",
    "\n",
    "| ![alt text](img/gridSearch.png \"Grid Search\")| \n",
    "|:--:| \n",
    "| **Grid Search**: Búsqueda a través de diferentes valores de dos hiperparámetros. Para cada hiperparámetro se consideran 10 valores diferentes (100 combinaciones distintas). Los contornos azules indican las regiones con mejores resultados, mientras que los rojos son regiones con peores resultados. Fuente de la imagen [wikipedia](https://es.m.wikipedia.org/wiki/Archivo:Hyperparameter_Optimization_using_Grid_Search.svg)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e35d29-a0c1-4981-8520-4dfcf8814379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = [\n",
    "{'criterion': [\"squared_error\", \"absolute_error\"]},\n",
    "{'max_features': [0.25, 0.5, 0.75, 1.0]}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model_tree, param_grid=param_grid,\n",
    "                           cv=[(np.arange(len(training_inputs)), np.arange(len(training_inputs),len(training_inputs)+ len(val_inputs)))])\n",
    "\n",
    "\n",
    "x=pd.concat([training_inputs, val_inputs])\n",
    "y=pd.concat([training_outputs, val_outputs])\n",
    "\n",
    "results=grid_search.fit(x,y)\n",
    "\n",
    "print(results)\n",
    "print(grid_search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476b8bd-832e-449a-95af-4098607355c3",
   "metadata": {},
   "source": [
    "#### Random Search\n",
    "\n",
    "\n",
    "| ![alt text](img/randomSearch.png \"Random Search\")| \n",
    "|:--:| \n",
    "| **Random Search**: Búsqueda aleatoria entre diferentes combinaciones de valores para dos hiperparámetros. En este ejemplo se evalúan 100 opciones aleatorias diferentes.Los contornos azules indican las regiones con mejores resultados, mientras que los rojos son regiones con peores resultados. Fuente de la imagen [wikipedia](https://commons.wikimedia.org/wiki/File:Hyperparameter_Optimization_using_Random_Search.svg)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda51f65-dcf1-4a5f-b60e-0f2743680d54",
   "metadata": {},
   "source": [
    "### Validación cruzada"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
