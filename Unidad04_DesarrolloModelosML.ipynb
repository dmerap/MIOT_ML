{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593bdb13-27df-45de-8eba-a9b88a0c41a8",
   "metadata": {},
   "source": [
    "![alt text](img/MIoT_ML.png \"MIoT_ML\")\n",
    "# Unidad 04  Entrenamiento de Modelos de Aprendizaje Automático\n",
    "\n",
    "El objetivo principal de esta práctica es el desarrollo, optimización y evaluación de un modelo de Aprendizaje Automático.\n",
    "\n",
    "El Notebook contiene varios ejercicios sencillos. Debéis desarrollarlos durante la clase y subirlos al aula virtual.\n",
    "\n",
    "## Referencias útiles para la práctica\n",
    "1. API Pandas: [https://pandas.pydata.org/docs/reference/index.html](https://pandas.pydata.org/docs/reference/index.html)\n",
    "2. API Scikit-learn: [https://scikit-learn.org/stable/api/index.html](https://scikit-learn.org/stable/api/index.html)\n",
    "3. Dataset para el ejercicio: [https://www.kaggle.com/datasets/camnugent/california-housing-prices](https://www.kaggle.com/datasets/camnugent/california-housing-prices)\n",
    "4. Géron, Aurélien. Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow. \" O'Reilly Media, Inc.\", 2022.\n",
    "5. Bergstra, J., & Bengio, Y. (2012). Random search for hyperparameter optimization. Journal of machine learning research, 13 (2). *Para profundizar en la optimización de hiperparámetros*\n",
    "   \n",
    "## 1. Flujo de trabajo básico en problemas de Aprendizaje Automático (*ML workflow*)\n",
    "A la hora de enfrentarnos a un nuevo problema de Aprendizaje Automático (ML), existen una serie de pasos típicos y comunes que debemos afrontar:\n",
    "1. Entender el problema y su contexto.\n",
    "2. Obtener los datos (histórico).\n",
    "3. Explorar, analizar y entender los datos.\n",
    "4. Preparar los datos para los modelos.\n",
    "5. Seleccionar, optimizar y entrenar los modelos ML.\n",
    "6. Evaluar y presentar el modelo seleccionado.\n",
    "7. Desplegar, monitorizar y mantener la solución.\n",
    "\n",
    "En esta unidad nos centraremos en los pasos 5 y 6 del flujo de trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5e0bf0-097f-41db-9f17-8abf8aeb723f",
   "metadata": {},
   "source": [
    "## 2. Carga y partición de datos\n",
    "### 2.1. Carga de los datos\n",
    "Cargaremos los datos generados durante la Unidad02, almacenados al finalizar la misma. Suponemos que se han mantenido los nombres generados durante dicha unidad, y que los datos están almacenados en el directorio raíz.\n",
    "\n",
    "- Características de entrada preprocesadas (*Inputs*) de las observaciones del conjunto de entrenamiento (*preprocessing_trainset_inputs.csv*).\n",
    "- Etiquetas de salida (*Outputs*) de las observaciones del conjunto de entrenamiento (*trainset_ouputs.csv*).\n",
    "- Características de entrada preprocesadas (*Inputs*) de las observaciones del conjunto de Test (*preprocessing_testset_inputs.csv*).\n",
    "- Etiquetas de salida (*Outputs*) de las observaciones del conjunto de Test (*testset_outputs.csv*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98859249-f101-4d2e-bc90-7b4309a4363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas library\n",
    "import pandas as pd\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError as err:\n",
    "    !pip install pandas\n",
    "    import pandas as pd\n",
    "\n",
    "\n",
    "training_inputs = pd.read_csv(\"./preprocessing_trainset_inputs.csv\", index_col=\"idx\")\n",
    "training_outputs = pd.read_csv(\"./trainset_ouputs.csv\", index_col=\"idx\")\n",
    "print(\"Longitud del conjunto de entrenamiento:\", len(training_inputs))\n",
    "\n",
    "testing_inputs = pd.read_csv(\"./preprocessing_testset_inputs.csv\", index_col=\"idx\")\n",
    "testing_outputs = pd.read_csv(\"./testset_outputs.csv\", index_col=\"idx\")\n",
    "print(\"Longitud del conjunto de test:\", len(testing_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18407a45-c5fa-4770-ac57-66053185940e",
   "metadata": {},
   "source": [
    "### 2.2. Creación del conjunto de validación\n",
    "\n",
    "Vamos a dividir el conjunto de test original en dos conjuntos de igual tamaño: el conjunto de validación, que emplearemos para seleccionar los hiperparámetros que den mejores resultados; y el conjunto de test propiamente dicho, que emplearemos para medir la calidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fbb504-b200-4845-89f3-dc48a3b8278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except ImportError as err:\n",
    "    !pip install sklearn\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED=1234\n",
    "\n",
    "# dividimos el conjunto de test original: testing_inputs\n",
    "test_inputs, val_inputs = train_test_split(testing_inputs, test_size=0.5, train_size=0.5, random_state=SEED, shuffle=True)\n",
    "\n",
    "# generamos los outputs correspondientes a los dos conjuntos creados\n",
    "val_outputs = testing_outputs.loc[val_inputs.index]\n",
    "print(\"Longitud del conjunto de validación:\", len(val_outputs))\n",
    "\n",
    "test_outputs = testing_outputs.loc[test_inputs.index]\n",
    "print(\"Longitud del conjunto de test:\", len(test_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549363f3-2526-48dd-b5f1-1aa0f66c8389",
   "metadata": {},
   "source": [
    "## 3. Creación y evaluación de un modelo básico\n",
    "\n",
    "### 3.1. Selección de una métrica de evaluación\n",
    "\n",
    "Para medir la calidad del modelo que vamos a desarrollar, necesitamos seleccionar una métrica que nos dé un valor que cuantifique la diferencia entre los datos conocidos del conjunto de test y los datos predichos por el modelo. En nuestro caso, vamos a emplear la métrica Root Mean Squared Error (en Scikit-learn está disponible mediante la función \"root_mean_squared_error\").\n",
    "\n",
    "![alt text](img/RMSE.png \"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3f1a8-207d-4a49-ac4b-1a253834ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e77dcc-c27e-42d4-bf26-bfad9d7bc26c",
   "metadata": {},
   "source": [
    "### 3.2. Creación y evaluación de un modelo básico\n",
    "#### 3.2.1. Creación de un modelo de regresión lineal\n",
    "\n",
    "Como dijimos en la unidad anterior, en la vida real normalmente no programaremos un modelo, sino que eligiremos uno de los muchos que hay en las librerías conocidas, como Scikit-learn. En este caso, vamos a elegir un modelo básico de regresión lineal multivariable (varios atributos de entrada), que en Scitkit-learn es implementado por la clase **LinerRegression**. Y llamaremos a su función *fit* pasándole las entradas y los valores reales (del conjunto de entrenamiento) para que entrene el modelo con esos datos y ajuste los parámetros del modelo.\n",
    "\n",
    "**Nota**: se puede añadir al propio pipeline de preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ede68-081e-4a2c-a8b0-b4073f60501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_lin_reg = LinearRegression()\n",
    "model_lin_reg.fit(training_inputs, training_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3c0f1c-47e7-464b-8d03-0c6e16ac0e90",
   "metadata": {},
   "source": [
    "#### 3.2.2. Evaluación con el dataset de entrenamiento\n",
    "\n",
    "Una vez entrenado el modelo con el conjunto de entrenamiento, podemos ver qué tal es su desempeño sobre el conjunto de entrenamiento (midiéndolo con la métrica RMSE). El grado de acierto sobre las primeras muestras:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3cd1c-b3f2-49f2-aa01-1d1c5b890490",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_predictions = model_lin_reg.predict(training_inputs)\n",
    "\n",
    "print(\"Primeras 5 observaciones del entrenamiento\")\n",
    "for real, pred in zip(training_predictions[:5].round(-2) ,training_outputs.iloc[:5].values):\n",
    "    print(f\"Valor real: {real}, valor predicho: {pred}. Diferencia en absoluto{abs(real-pred)}. Porcentaje desvío: {(abs(real-pred)*100/real).round(2)}%\")\n",
    "\n",
    "# lin_reg_rmse = root_mean_squared_error(traini)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d397f8d7-da9d-4076-b843-a86832d601da",
   "metadata": {},
   "source": [
    "Y el grado de acierto sobre todo el dataset de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7467dd-0e9d-47ba-809f-4cef8ff4533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rmse_train = root_mean_squared_error(training_outputs, training_predictions)\n",
    "print(f\"RMSE de entrenamiento con modelo de regresión lineal: {rmse_train.round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83b03ba-19bb-4045-b1b5-55b4fd415688",
   "metadata": {},
   "source": [
    "#### 3.2.3. Evaluación con un conjunto de datos no visto previamente\n",
    "\n",
    "Veamos ahora cómo se comporta el modelo con un conjunto de datos que no ha visto durante el entrenamiento, por ejemplo, el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d49d84-5dbd-49c6-af0d-d5181b90e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación con el dataset de Validación para el modelo de regresión lineal\n",
    "val_predictions = model_lin_reg.predict(val_inputs)\n",
    "rmse_val = root_mean_squared_error(val_outputs, val_predictions)\n",
    "print(f\"RMSE de Validación con modelo de regresión lineal: {rmse_val.round(2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31574e1a-6928-4237-a3ab-00b0f8589c85",
   "metadata": {},
   "source": [
    "### 3.3. Creación y evaluación de otro modelo (DecisionTree)\n",
    "\n",
    "Veamos ahora otro modelo de predicción, un árbol de decisión.\n",
    "\n",
    "#### 3.3.1. Creación del modelo de árbol de decisión\n",
    "\n",
    "Para esta tarea, tenemos la clase *DecisionTreeRegressor* del Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c67395-6142-40f6-9f5f-bc3c3a816ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model_tree = DecisionTreeRegressor(random_state=SEED)\n",
    "model_tree.fit(training_inputs, training_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3ffc6b-777e-44ed-96a7-cb0c9942d542",
   "metadata": {},
   "source": [
    "#### 3.3.2. Evaluación con el dataset de entrenamiento\n",
    "\n",
    "Una vez entrenado el modelo con el conjunto de entrenamiento, podemos ver qué tal es su desempeño sobre el conjunto de entrenamiento (midiéndolo con la métrica RMSE). El grado de acierto sobre las primeras muestras y sobre todo el conjunto de entrenamiento es:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe963bb-0a8a-4865-a778-153b2bc90110",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = model_tree.predict(training_inputs)\n",
    "\n",
    "print(\"Primeras 5 observaciones del entrenamiento\")\n",
    "for real, pred in zip(training_predictions[:5].round(-2),training_outputs.iloc[:5].values):\n",
    "    print(f\"Valor real: {real}, valor predicho: {pred}. Diferencia en absoluto{abs(real-pred)}. Porcentaje desvío: {(abs(real-pred)*100/real).round(2)}%\")\n",
    "\n",
    "rmse_train  =root_mean_squared_error(training_outputs, training_predictions)\n",
    "print(f\"RMSE de entrenamiento con modelo de árbol de decisión: {rmse_train.round(2)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5ebd9-cdaf-4c80-a800-2d0581311d7c",
   "metadata": {},
   "source": [
    "**¿Qué ha pasado? ¿Cómo puede ser que no tenga ningún error?**\n",
    "\n",
    "**EJERCICIO**\n",
    "Explica en una celda de texto qué puede estar pasando para que no exista error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67121e97-976d-42e9-adbc-00694f8dc548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO\n",
    "# Explica en esta celda de texto que puede estar pasando para que no exista error\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3991fc6e-cb3c-4a75-96e1-3f7ae73ad381",
   "metadata": {},
   "source": [
    "#### 3.3.3. Evaluación con un conjunto de datos no visto previamente\n",
    "\n",
    "Veamos ahora cómo se comporta el modelo con un conjunto de datos que no ha visto durante el entrenamiento, por ejemplo, el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d797236-23f9-4b06-8ed8-9e107a2a89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_predictions = model_tree.predict(val_inputs)\n",
    "rmse_val = root_mean_squared_error(val_outputs, val_predictions)\n",
    "print(f\"RMSE de Validación con el modelo árbol de decisión: {rmse_val.round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bacc25-0196-4230-a689-98f9be8332da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc0a1abb-af82-4f7b-a83a-ac6963044a75",
   "metadata": {},
   "source": [
    "## 4. Selección de características\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598a6f5c-b801-4ab4-a014-b011ba9bdc2d",
   "metadata": {},
   "source": [
    "#### Filtros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00f30c4-cce4-43e9-bd9a-6100a2e371bc",
   "metadata": {},
   "source": [
    "#### Embebidos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0468f-42b1-47c5-a54b-53c269cec631",
   "metadata": {},
   "source": [
    "#### Wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34022bb-8464-4291-8d63-ad302adcc0fb",
   "metadata": {},
   "source": [
    "### Optimización de hiperparámetros\n",
    "Los algoritmos de ML tienen una serie de parámetros de configuración que afectan al entrenamiento del modelo y posteriormente al desempeño de este (ej. LR, momento, etc.). Los parámetros por defecto raras veces son los óptimos, y es necesario optimizarlos para cada problema concreto. Este es un proceso muy costoso computacionalmente, y que requiere muchas veces de recursos dedicados. Existen diferentes técnicas para realizar la optimización (ej. GRID, aleatoria, evolutiva, etc.). La más básica es la optimización basada en una búsqueda GRID.\n",
    "\n",
    "#### Grid Search\n",
    "\n",
    "La optimización GRID es la prueba exhaustiva de todas las combinaciones posibles de varios parámetros. Para aplicarla, lo primero que necesitamos es establecer los rangos de valores que queremos probar. La prueba exhaustiva es el equivalente a probar todas las combinaciones empleando bucles “for” anidados. Las optimizaciones de hiperparámetros se hacen y se comparan a través de un conjunto de validación (o empleando validación cruzada), pero nunca contra el conjunto de test).\n",
    "\n",
    "\n",
    "| ![alt text](img/gridSearch.png \"Grid Search\")| \n",
    "|:--:| \n",
    "| **Grid Search**: Búsqueda a través de diferentes valores de dos hiperparámetros. Para cada hiperparámetro se consideran 10 valores diferentes (100 combinaciones distintas). Los contornos azules indican las regiones con mejores resultados, mientras que los rojos son regiones con peores resultados. Fuente de la imagen [wikipedia](https://es.m.wikipedia.org/wiki/Archivo:Hyperparameter_Optimization_using_Grid_Search.svg)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e35d29-a0c1-4981-8520-4dfcf8814379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "param_grid = [\n",
    "{'criterion': [\"squared_error\", \"absolute_error\"]},\n",
    "{'max_features': [0.25, 0.5, 0.75, 1.0]}\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model_tree, param_grid=param_grid,\n",
    "                           cv=[(np.arange(len(training_inputs)), np.arange(len(training_inputs),len(training_inputs)+ len(val_inputs)))])\n",
    "\n",
    "\n",
    "x=pd.concat([training_inputs, val_inputs])\n",
    "y=pd.concat([training_outputs, val_outputs])\n",
    "\n",
    "results=grid_search.fit(x,y)\n",
    "\n",
    "print(results)\n",
    "print(grid_search.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476b8bd-832e-449a-95af-4098607355c3",
   "metadata": {},
   "source": [
    "#### Random Search\n",
    "\n",
    "\n",
    "| ![alt text](img/randomSearch.png \"Random Search\")| \n",
    "|:--:| \n",
    "| **Random Search**: Búsqueda aleatoria entre diferentes combinaciones de valores para dos hiperparámetros. En este ejemplo se evalúan 100 opciones aleatorias diferentes.Los contornos azules indican las regiones con mejores resultados, mientras que los rojos son regiones con peores resultados. Fuente de la imagen [wikipedia](https://commons.wikimedia.org/wiki/File:Hyperparameter_Optimization_using_Random_Search.svg)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda51f65-dcf1-4a5f-b60e-0f2743680d54",
   "metadata": {},
   "source": [
    "### Validación cruzada"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
