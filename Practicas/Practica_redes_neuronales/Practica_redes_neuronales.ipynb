{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30669d70",
   "metadata": {},
   "source": [
    "## 1.\tMNIST: ejemplo de clasificación de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2107c816",
   "metadata": {},
   "source": [
    "### 1.2. MNIST dataset \n",
    "\n",
    "* El MNIST (Modified National Institute of Standards and Technology) es una base de datos de dígitos manuscritos.\n",
    "* Se utiliza habitualmente para entrenar y probar sistemas de procesamiento de imágenes en el campo del aprendizaje automático. Se podría decir que es el *Hello World* de este campo.\n",
    "* Se compone de 60.000 imágenes de entrenamiento y 10.000 imágenes de prueba.\n",
    "* Cada imagen tiene unas dimensiones de 28x28 píxeles en escala de grises y representa uno de los diez dígitos posibles (del 0 al 9).\n",
    "  \n",
    "<!--- * El conjunto de entrenamiento será un tensor 3D de `(60000, 28, 28)` y el conjunto de test un tensor 3D de `(10000, 28, 28)` siendo el `dtype` un `uint8`. --->\n",
    "\n",
    "<img src=\"images/classical_nn_implementation/mnist.png\" width=594 height=361/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c718aa3",
   "metadata": {},
   "source": [
    "*  Los datos MNIST se precargan en Keras en forma de cuatro arrays NumPy: dos pares para entrenamiento y dos pares para test\n",
    "* Cada par (entrenamiento o test) tiene un array para almacenar los datos de la imagen y un array con las etiquetas correspondientes a cada imagen.\n",
    "* Importamos el paquete `mnist` que almacena los datos correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bedd14a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a184611d",
   "metadata": {},
   "source": [
    "* Cargamos los datos de entrenamiento y los datos de prueba como un objeto NumPy `ndarray`.\n",
    "* NumPy (http://www.numpy.org/) es el paquete fundamental para la computación científica con Python.\n",
    "*  Contiene, entre otras cosas:\n",
    " - Un objeto para representar arrays n-dimensionales (`ndarray`) eficientemente.\n",
    "    - Operaciones aritméticas rápidas orientadas a arrays con capacidades de difusión flexibles.\n",
    "    - Funciones matemáticas que permiten realizar eficientemente operaciones sobre arrays sin tener que escribir bucles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f7fbed0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "416889ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b1d70",
   "metadata": {},
   "source": [
    "* Veamos los datos de entrenamiento.\n",
    "* `shape` es un atributo de `ndarray`.\n",
    "* Contiene una tupla de enteros indicando el tamaño de cada una de las dimensiones del array. \n",
    "* La longitud de la tupla será el número de dimensiones de la matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49725a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb7c50f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "454da8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345b0704",
   "metadata": {},
   "source": [
    "* Los datos para el test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da497504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5bf97cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2e2daac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83edb26f",
   "metadata": {},
   "source": [
    "### 1.3. Preparando los datos \n",
    "\n",
    "* Necesitamos preparar los datos a lo que la red espera de ellos.\n",
    "* Las imágenes son un array de dimensiones `(60000, 28, 28)` de tipo `uint8` con valores de `[0, 255]`.\n",
    "* En  primer lugar, deben ser transformadas en una matriz de dimensiones `(60000, 28 * 28)` \n",
    " - La imagen se aplana a una simple matriz de `28 * 28 = 784` valores.\n",
    "  - Usamos la función NumPy `reshape` que cambia la forma de un array sin cambiar sus datos (https://numpy.org/doc/stable/reference/generated/numpy.reshape.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c48608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "test_images = test_images.reshape((10000, 28 * 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0e603f",
   "metadata": {},
   "source": [
    "* En segundo lugar, deben ser transformados a un tipo float `float32` con valores entre 0 y 1.\n",
    "    - Cada valor va de 0 a 255 (niveles de gris) y debe ser normalizado a valores entre 0 y 1 (dividiendo por 255).\n",
    "    - Usamos la función NumPy `astype` que copia el array y cast sus valores a un tipo especificado.\n",
    "    - Cuando dividimos un `ndarray` por un número dividimos cada elemento del array por ese número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6521b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2246e92",
   "metadata": {},
   "source": [
    "* También necesitamos codificar categóricamente las etiquetas utilizando la codificación *one-hot*.\n",
    "* En esta codificación convertimos un entero en una matriz de enteros en la que todos los valores se ponen a cero excepto el valor que correspondía al entero original que se pone a uno.\n",
    "* Usamos la función `to_categorical` que convierte enteros en una matriz binaria de clases (https://keras.io/api/utils/python_utils/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b61cd9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14ad993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e34cbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b214eb",
   "metadata": {},
   "source": [
    "### 1.4. Building the Model and Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93802d9f",
   "metadata": {},
   "source": [
    "#### Modelo secuencial\n",
    "\n",
    "\n",
    "* Utilizaremos el modelo secuencial de Keras.\n",
    "* Usaremos la clase `Sequential` (https://keras.io/api/models/sequential/) para crear el modelo secuencial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a090ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174277c",
   "metadata": {},
   "source": [
    "#### Capa de entrada\n",
    "* La primera capa que se debe crear es una capa de entrada que recibe la entrada (https://keras.io/api/layers/core_layers/input/).\n",
    "* El parámetro más importante en el constructor de `Input` es `shape`, una tupla de enteros que indica la forma de la entrada.\n",
    "* Por ejemplo, `shape=(784,)` indica que la entrada esperada serán lotes de vectores de 784 dimensiones (nuestras imágenes de 28x28).\n",
    "* Los elementos de esta tupla pueden ser `None`, representando dimensiones donde la forma no es conocida.\n",
    "* Añadimos este capa al modelo usando el método `add`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecf76cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Input(shape=(784, )))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a561dacb",
   "metadata": {},
   "source": [
    "#### Capas densas\n",
    "\n",
    "* Las capas densas son capas formadas por neuronas artificiales, cada una está completamente conectada con las capas anteriores y posteriores.\n",
    "* En Keras, `Dense` (https://keras.io/api/layers/core_layers/dense/) representa una capa de red neuronal densamente conectada que implementa la operación `output = activation(dot(input, kernel) + bias)`.\n",
    "* Los parámetros típicos para el constructor `Dense` son:\n",
    "    - units: el número de neuronas en la capa.\n",
    "    - activation: la función de activación utilizada en cada neurona.\n",
    "    - input_shape: cuando se pasa, Keras creará una capa de entrada para insertar antes de la capa actual. Esto puede tratarse como equivalente a definir explícitamente una capa `Input`.\n",
    "* En este caso, vamos a crear una capa densa que recibe 784 entradas y produce 512 salidas activadas por la función ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f514213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(512, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32284114",
   "metadata": {},
   "source": [
    "#### Capa de salida\n",
    "\n",
    "* La capa de salida también es una capa densa, pero en este caso con 10 neuronas, cada una de las cuales representará un dígito.\n",
    "* El valor de salida de cada neurona de la capa de salida indicará la probabilidad de que el dígito actual corresponda al dígito representado por esa neurona.\n",
    "* La probabilidad total debe sumar uno.\n",
    "* Para obtener estos valores, utilizamos la función de activación *softmax*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8dce5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a14804",
   "metadata": {},
   "source": [
    "#### Función de activación softmax\n",
    "\n",
    "* La función softmax o función exponencial normalizada convierte un vector de $K$ números reales en una distribución de probabilidad de $K$ resultados posibles.\n",
    "\n",
    "* La función softmax se utiliza a menudo como la última función de activación de una red neuronal para normalizar la salida de una red a una distribución de probabilidad sobre las clases de salida predichas.\n",
    "\n",
    "* La función softmax estándar $\\sigma : \\mathbb{R}^K \\to (0, 1)^K$ se define cuando $K \\ge 1$ mediante la fórmula:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^K e^{z_j}} \\ \\ \\text{ para } i = 1, \\dotsc, K \\text{ y } \\mathbf{z} = (z_1, \\dotsc, z_K) \\in \\mathbb{R}^K.\n",
    "\\end{equation*}\n",
    "\n",
    "<img src=\"images/classical_nn_implementation/softmax.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae253fd",
   "metadata": {},
   "source": [
    "#### Resumen del modelo\n",
    "\n",
    "* Podemos observar un resumen de nuestro modelo utilizando la función `summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94b7319e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d959206b",
   "metadata": {},
   "source": [
    "### 1.5. Proceso de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db805b1",
   "metadata": {},
   "source": [
    "#### Definiendo los parámetros de aprendizaje\n",
    "\n",
    "* Antes de entrenar un modelo, es necesario configurar el proceso de aprendizaje, lo cual se hace a través del método `compile`.\n",
    "* Necesitamos elegir tres cosas más como parte del paso de compilación:\n",
    "    - Una **función de pérdida**: Cómo el modelo podrá medir su rendimiento en los datos de entrenamiento y, por lo tanto, cómo podrá orientarse en la dirección correcta.\n",
    "    - Un **optimizador**: El mecanismo a través del cual el modelo se actualizará en función de los datos de entrenamiento que vea, para mejorar su rendimiento.\n",
    "    - **Métricas** para monitorear durante el entrenamiento y la prueba. Aquí, solo nos importará la precisión (la fracción de las imágenes que fueron clasificadas correctamente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f111aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", \n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da43224",
   "metadata": {},
   "source": [
    "#### Entrenamiento\n",
    "\n",
    "* Ahora estamos listos para entrenar el modelo, lo cual en Keras se hace a través de una llamada al método `fit()` del modelo; ajustamos el modelo a sus datos de entrenamiento.\n",
    "\n",
    "* Los parámetros principales del método `fit()` son (https://keras.io/api/models/model_training_apis/):\n",
    "    - Los **datos de entrada**: las imágenes de entrenamiento.\n",
    "    - Los **datos objetivo**: las etiquetas de entrenamiento.\n",
    "    - Las **épocas**: Número de iteraciones sobre todos los datos de entrada y objetivo. \n",
    "        * Al usar los datos de entrada varias veces, aumentamos la precisión de nuestro modelo. \n",
    "        * Pero debemos tener cuidado de no causar sobreajuste.\n",
    "    - El **tamaño del lote**: Número de muestras por actualización de gradiente.\n",
    "        * Con un tamaño de lote de 1, actualizamos los pesos de la red después de que cada muestra ha pasado a través de la red, esto es lento y consume muchos recursos.\n",
    "        * Podemos agrupar los datos de entrada en lotes y solo actualizar los pesos después de que todas las muestras del lote hayan ingresado a la red.\n",
    "        * El aprendizaje consume menos recursos, pero dado que estamos propagando hacia atrás el error promedio de todas las muestras del lote, la calidad del modelo puede degradarse y, en última instancia, puede no ser capaz de generalizar bien en datos que no ha visto antes.\n",
    "\n",
    "* Se muestran dos cantidades durante el entrenamiento: la pérdida del modelo sobre los datos de entrenamiento y la precisión del modelo sobre los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3373eaa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8698 - loss: 0.4483\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.1117\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9783 - loss: 0.0745\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.0512\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2628662ee10>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b6db6e7-8e34-4e10-bc4b-1639f868ae97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9771 - loss: 0.0756\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f826a3-959f-4e5b-b903-ce989fb8c317",
   "metadata": {},
   "source": [
    "# 2. Práctica a realizar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de8ff9-2ce7-463c-83f1-5a1ac6d5c0bc",
   "metadata": {},
   "source": [
    "* Ahora, trataremos de implementar un modelo de red neuronal para el dataset **Fashion-MNIST**:\n",
    "\n",
    "    - Fashion-MNIST es un conjunto de imágenes sobre diferentes artículos. Consta de un conjunto de entrenamiento de 60,000 ejemplos y un conjunto de prueba de 10,000 ejemplos.\n",
    "     \n",
    "    - Cada ejemplo es una imagen en escala de grises de 28x28, asociada con una etiqueta de las siguientes 10 clases: (0) Camiseta/top, (1) Pantalón, (2) Suéter, (3) Vestido, (4) Abrigo, (5) Sandalia, (6) Camisa, (7) Zapatilla, (8) Bolsa y (9) Botín.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/classical_nn_implementation/dataset-cover.png\" width=800 />\n",
    "\n",
    "\n",
    "* El conjunto de datos se puede descargar fácilmente desde Keras utilizando las siguientes instrucciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd5f3b8-f3e2-4caa-8b9c-c813d46a01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Cargar el dataset de Fashion MNIST\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbbc316-bdf8-46f5-9da1-2faeb866be5f",
   "metadata": {},
   "source": [
    "* A partir de aquí, debereis de completar los siguientes apartados:\n",
    "\n",
    "1. Preprocesamiento.\n",
    "    - Preprocesar el conjunto de datos para prepararlo para alimentar la red neuronal: aplanar las imágenes, convertir enteros a valores flotantes, codificar las etiquetas utilizando la codificación one-hot, etc.\n",
    "    - Dividir los datos de entrenamiento en entrenamiento y validación, utilizando este último como referencia para la afinación de hiperparámetros.\n",
    "<br></br>\n",
    "2. Desarrollo del modelo.\n",
    "    - Decidir los hiperparámetros estructurales de la red: capas, neuronas por capa, funciones de activación, etc.\n",
    "    - Decidir los hiperparámetros de aprendizaje de la red: optimizador, tasa de aprendizaje, épocas, tamaño de lote, métricas, etc.\n",
    "    - Justificar las decisiones tomadas.\n",
    "<br></br>\n",
    "\n",
    "3. Resultados.\n",
    "    - Ejecutar y comentar los resultados obtenidos en cada paso.\n",
    "    - Decidir qué métrica sería más útil para el problema en cuestión.\n",
    "    - Hablar sobre posibles acciones a tomar para mejorar los valores: Técnicas de regularización, aumento/reducción de los conjuntos usados... \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
